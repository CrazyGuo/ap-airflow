version: 2.1
workflows:
  version: 2.1
  
  regression:
    jobs:
      - waiter
      - certified-ui-regression:
          requires: 
            - waiter
      - certified-rest-api:
          requires: 
            - waiter
      - certified-core-dags:
          requires: 
            - waiter

  certified-airflow:
    jobs:
      - static-checks
{% for ac_version, distributions in image_map.items() %}
{% set airflow_version = ac_version | get_airflow_version -%}
{% set docker_repo = "astronomerio/ap-airflow" if "dev" in ac_version else "astronomerinc/ap-airflow" -%}
{% for distribution in distributions %}
      - build:
          name: build-{{ airflow_version }}-{{ distribution }}
          airflow_version: {{ airflow_version }}
          distribution_name: {{ distribution }}
          docker_repo: {{ docker_repo }}
          {%- if "dev" in ac_version and airflow_version not in dev_allowlist %}
          extra_args: "--build-arg VERSION=$(curl https://pip.astronomer.io/simple/astronomer-certified/latest-{{ airflow_version | replace('.dev', '') }}.build)"
          {%- endif %}
          requires:
            - static-checks
      - scan:
          name: scan-{{ airflow_version }}-{{ distribution }}-onbuild
          airflow_version: {{ airflow_version }}
          distribution_name: {{ distribution }}-onbuild
          docker_repo: {{ docker_repo }}
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - scan-trivy:
          name: scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
          airflow_version: {{ airflow_version }}
          docker_repo: {{ docker_repo }}
          distribution: {{ distribution }}
          distribution_name: {{ distribution }}-onbuild
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - test:
          name: test-{{ airflow_version }}-{{ distribution }}-images
          docker_repo: {{ docker_repo }}
          tag: "{{ airflow_version }}-{{ distribution }}"
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - publish:
          name: publish-{{ airflow_version }}-{{ distribution }}
          docker_repo: {{ docker_repo }}
          tag: "{{ airflow_version }}-{{ distribution }}"
          {%- if "dev" in airflow_version %}
          extra_tags: "{{ airflow_version }}-{{ distribution }}-${CIRCLE_BUILD_NUM}"
          {%- else %}
          extra_tags: "{{ airflow_version }}-{{ distribution }}-${CIRCLE_BUILD_NUM},{{ ac_version }}-{{ distribution }}"
          {%- endif %}
          requires:
            - scan-{{ airflow_version }}-{{ distribution }}-onbuild
            - scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
            - test-{{ airflow_version }}-{{ distribution }}-images
          filters:
            branches:
              only: master
      - publish:
          name: publish-{{ airflow_version }}-{{ distribution }}-onbuild
          docker_repo: {{ docker_repo }}
          tag: "{{ airflow_version }}-{{ distribution }}-onbuild"
          {%- if "dev" in airflow_version %}
          extra_tags: "{{ airflow_version }}-{{ distribution }}-onbuild-${CIRCLE_BUILD_NUM}"
          {%- else %}
          extra_tags: "{{ airflow_version }}-{{ distribution }}-onbuild-${CIRCLE_BUILD_NUM},{{ ac_version }}-{{ distribution }}-onbuild"
          {%- endif %}
          requires:
            - scan-{{ airflow_version }}-{{ distribution }}-onbuild
            - scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
            - test-{{ airflow_version }}-{{ distribution }}-images
          filters:
            branches:
              only: master
{% endfor %}
{% endfor %}
{% if image_map.keys() | dev_releases | length > 0 %}
  nightly:
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
{%- for ac_version, distributions in image_map.items() %}
{%- set airflow_version = ac_version | get_airflow_version %}
{%- if "dev" in ac_version and airflow_version not in dev_allowlist  %}
{%- for distribution in distributions %}
      - build:
          name: build-{{ airflow_version }}-{{ distribution }}
          airflow_version: {{ airflow_version }}
          distribution_name: {{ distribution }}
          docker_repo: "astronomerio/ap-airflow"
          extra_args: "--build-arg VERSION=$(curl https://pip.astronomer.io/simple/astronomer-certified/latest-{{ airflow_version | replace('.dev', '') }}.build)"
      - scan:
          name: scan-{{ airflow_version }}-{{ distribution }}-onbuild
          airflow_version: {{ airflow_version }}
          distribution_name: {{ distribution }}-onbuild
          docker_repo: "astronomerio/ap-airflow"
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - scan-trivy:
          name: scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
          airflow_version: {{ airflow_version }}
          docker_repo: "astronomerio/ap-airflow"
          distribution: {{ distribution }}
          distribution_name: {{ distribution }}-onbuild
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - test:
          name: test-{{ airflow_version }}-{{ distribution }}-images
          docker_repo: "astronomerio/ap-airflow"
          tag: "{{ airflow_version }}-{{ distribution }}"
          requires:
            - build-{{ airflow_version }}-{{ distribution }}
      - publish:
          name: publish-{{ airflow_version }}-{{ distribution }}
          docker_repo: "astronomerio/ap-airflow"
          tag: "{{ airflow_version }}-{{ distribution }}"
          extra_tags: "{{ airflow_version }}-{{ distribution }}-${CIRCLE_BUILD_NUM}"
          requires:
            - scan-{{ airflow_version }}-{{ distribution }}-onbuild
            - scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
            - test-{{ airflow_version }}-{{ distribution }}-images
          filters:
            branches:
              only: master
      - publish:
          name: publish-{{ airflow_version }}-{{ distribution }}-onbuild
          docker_repo: "astronomerio/ap-airflow"
          tag: "{{ airflow_version }}-{{ distribution }}-onbuild"
          extra_tags: "{{ airflow_version }}-{{ distribution }}-onbuild-${CIRCLE_BUILD_NUM},{{ ac_version }}-{{ distribution }}-onbuild"
          requires:
            - scan-{{ airflow_version }}-{{ distribution }}-onbuild
            - scan-trivy-{{ airflow_version }}-{{ distribution }}-onbuild
            - test-{{ airflow_version }}-{{ distribution }}-images
          filters:
            branches:
              only: master
{%- endfor %}
{% endif %}
{%- endfor %}
{% endif %}
jobs:

  waiter:
    executor: python/default
    resource_class: small
    steps:
      #- run: sleep 120
      - wait_workflow_orb:
          workflow-name: certified-airflow
          max-wait-time: '100000'
          sleep-time-between-checks: '60'
          branch-to-consider: master
  static-checks:
    executor: machine-executor
    description: Static Checks
    steps:
      - checkout
      - run:
          name: Load archived Docker image
          command: |
            pyenv global 3.7.0
            pip install -r .circleci/test-requirements.txt
            pre-commit run --all-files
  build:
    executor: docker-executor
    description: Build Airflow images
    parameters:
      airflow_version:
        description: "The Airflow version, for example '1.10.5'"
        type: string
      distribution_name:
        description: "The base distribution of the container"
        type: string
      docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
      extra_args:
        description: "Extra args to pass to pass to Docker build command"
        default: ""
        type: string
    steps:
      - docker-build-base-and-onbuild:
          airflow_version: "<< parameters.airflow_version >>"
          distribution_name: "<< parameters.distribution_name >>"
          docker_repo: "<< parameters.docker_repo >>"
          extra_args: "<< parameters.extra_args >>"
  test:
    executor: machine-executor
    description: Test Airflow images
    parameters:
      docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
      tag:
        type: string
    steps:
      - airflow-image-test:
          repository: "<< parameters.docker_repo >>"
          tag: "<< parameters.tag >>"
  scan:
    executor: clair-scanner/default
    description: Test Airflow images
    parameters:
      airflow_version:
        description: "The Airflow version, for example '1.10.5'"
        type: string
      distribution_name:
        description: "The base distribution of the container"
        type: string
      docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
    steps:
      - clair-scan:
          image_name: "<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>"
  scan-trivy:
    docker:
      - image: docker:18.09-git
    description: "Trivy: Vulnerability scanner a Docker image"
    parameters:
      airflow_version:
        description: "The Airflow version, for example '1.10.5'"
        type: string
      docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
      distribution_name:
        description: "The base distribution of the container"
        type: string
      distribution:
        description: "The distribution without onbuild"
        type: string
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load archived Docker image
          command: docker load -i /tmp/workspace/saved-images/<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>.tar
      - run:
          name: Install trivy
          command: |
            apk add --update-cache --upgrade curl rpm
            curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/master/contrib/install.sh | sh -s -- -b /usr/local/bin
      - restore_cache:
          keys:
            - trivy-cache
      - run:
          name: Scan the local image with trivy
          command: |
            trivy --ignorefile ./<< parameters.airflow_version >>/<< parameters.distribution >>/trivyignore --cache-dir /tmp/workspace/trivy-cache --ignore-unfixed -s HIGH,CRITICAL --exit-code 1 --no-progress "<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>"
      - save_cache:
          key: trivy-cache
          paths:
            - /tmp/workspace/trivy-cache
  publish:
    executor: docker-executor
    description: Publish Airflow images
    parameters:
      tag:
        type: string
      extra_tags:
        type: string
        default: ""
      docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
      dev_docker_repo:
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        default: "astronomerio/ap-airflow"
        type: string
    steps:
      - push:
          extra_tags: "<< parameters.extra_tags >>"
          tag: "<< parameters.tag >>"
          prod_docker_repo: "<< parameters.docker_repo >>"
          dev_docker_repo: "<< parameters.dev_docker_repo >>"
  
orbs:
  clair-scanner: ovotech/clair-scanner@1.6.0
executors:
  docker-executor:
    docker:
      - image: circleci/python:3
  machine-executor:
    machine:
      image: ubuntu-1604:201903-01
commands:

  docker-build-base-and-onbuild:
    description: "Build Airflow images to use with the Astronomer platform"
    parameters:
      airflow_version:
        type: string
        default: 1.10.5
      distribution_name:
        type: string
        default: alpine
      docker_repo:
        default: "astronomerinc/ap-airflow"
        description: "The docker repo to publish the image, for example 'astronomerinc/ap-airflow'"
        type: string
      extra_args:
        description: "Extra args to pass to pass to Docker build command"
        default: ""
        type: string
    steps:
      - checkout
      - setup_remote_docker:
          docker_layer_caching: true
      - docker-build:
          image_name: "<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>"
          path: "<< parameters.airflow_version >>/<< parameters.distribution_name >>"
          extra_args: "<< parameters.extra_args >>"
      - docker-build:
          image_name: "<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>-onbuild"
          path: "common/"
          dockerfile: "Dockerfile.onbuild-<< parameters.distribution_name >>"
          extra_args: "--build-arg baseimage=<< parameters.docker_repo >>:<< parameters.airflow_version >>-<< parameters.distribution_name >>"
      - persist_to_workspace:
          root: .
          paths:
            - saved-images/
  docker-build:
    description: "Build a Docker image"
    parameters:
      dockerfile:
        type: string
        default: Dockerfile
      path:
        type: string
        default: "."
      image_name:
        type: string
        default: $CIRCLE_PROJECT_REPONAME
      extra_args:
        type: string
        default: ""
    steps:
      - run:
          name: Build the Docker image
          command: |
            set -xe
            mkdir -p saved-images/"$(dirname "<< parameters.image_name >>")"
            docker build -t "<< parameters.image_name >>" --file << parameters.path>>/<< parameters.dockerfile >> --build-arg BUILD_NUMBER=${CIRCLE_BUILD_NUM} --build-arg REPO_BRANCH=${CIRCLE_BRANCH} << parameters.extra_args >> << parameters.path >>
            docker save -o saved-images/<< parameters.image_name >>.tar << parameters.image_name >>
  airflow-image-test:
    description: Test an Airflow image
    parameters:
      repository:
        type: string
      tag:
        type: string
    steps:
      - checkout
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load archived Airflow Docker image
          command: |
            docker load -i /tmp/workspace/saved-images/<< parameters.repository >>:<< parameters.tag >>.tar
            docker load -i /tmp/workspace/saved-images/<< parameters.repository >>:<< parameters.tag >>-onbuild.tar
      - run:
          name: Test Airflow Docker images (Base + Onbuild)
          command: |
            set -e
            pyenv global 3.7.0
            pip install -r .circleci/test-requirements.txt
            .circleci/bin/test-airflow << parameters.repository >> << parameters.tag >>
      - store_test_results:
          path: /tmp/test-reports
  push:
    description: "Push a Docker image to DockerHub"
    parameters:
      extra_tags:
        type: string
        default: ""
      tag:
        type: string
      prod_docker_repo:
        type: string
      dev_docker_repo:
        default: "astronomerio/ap-airflow"
        type: string
    steps:
      - attach_workspace:
          at: /tmp/workspace
      - setup_remote_docker
      - run:
          name: Load archived Docker image
          command: docker load -i '/tmp/workspace/saved-images/<< parameters.prod_docker_repo >>:<< parameters.tag >>.tar'
      - run:
          name: Login to DockerHub
          command: echo "$DOCKER_PASSWORD" | docker login --username $DOCKER_USERNAME --password-stdin
      - run:
          name: Push Docker image(s)
          command: |
            set -e
            image="<< parameters.prod_docker_repo >>:<< parameters.tag >>"
            set -x
            export NEW_POINT_RELEASE=true
            for tag in $(echo "<< parameters.extra_tags >>" | sed "s/,/ /g");
            do
              if DOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect << parameters.prod_docker_repo >>:$tag >/dev/null 2>&1; then
                echo "Image with Tag (<< parameters.prod_docker_repo >>:$tag) already exists"
                export NEW_POINT_RELEASE=false
              elif [[ "$tag" == "<< parameters.tag >>-$CIRCLE_BUILD_NUM" ]]; then
                echo "Pushing Image with << parameters.tag >>-$CIRCLE_BUILD_NUM tag to << parameters.dev_docker_repo >>"
                docker tag "$image" "<< parameters.dev_docker_repo >>:${tag}"
                docker push "<< parameters.dev_docker_repo >>:${tag}"
              else
                docker tag "$image" "<< parameters.prod_docker_repo >>:${tag}"
                docker push "<< parameters.prod_docker_repo >>:${tag}"
              fi
            done
            if $NEW_POINT_RELEASE ; then
              docker push "$image"
            else
              echo "Image with Tag ($image) not pushed as it is not a new point release"
            fi
            set +x
  clair-scan:
    description: "Vulnerability scan a Docker image"
    parameters:
      image_name:
        type: string
        default: $CIRCLE_PROJECT_REPONAME
      allowlist:
        type: string
        default: cve-allowlist.yaml
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: Load archived Docker image
          command: docker load -i /tmp/workspace/saved-images/<< parameters.image_name >>.tar
      - modified-orb:
          allowlist: "<< parameters.allowlist >>"
          image: "<< parameters.image_name >>"
  certified-ui-regression:
    description: "Run UI Regression Tests using Testim"
    environment:
      CIRCLE_TEST_REPORTS: /tmp/circleci-test-results
    executor: machine-executor
    steps:
      - run: sudo apt-get -y update
      - run: sudo apt-get -y install git
      - run: sudo apt-get -y install curl
      - run: curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -
      - run: sudo apt-get install nodejs
      - run: npm -v
      - run: nodejs -v
      - run: 
          name: Avoid hosts unknown for github
          command:   | 
            [ ! -d ~/.ssh ] && mkdir ~/.ssh/
            echo -e "Host github.com\n\tStrictHostKeyChecking no\n" > ~/.ssh/config  
      - run: git clone git@github.com:astronomer/qa-regression.git
      - run: 
          name: Run Shell Script for creating deployment
          command:  |
            cd qa-regression
            ls
            chmod 744 create_deployment.sh
            bash ./create_deployment.sh
            cd ..
      - run: mkdir -p $CIRCLE_TEST_REPORTS/testim/
      - run: 
          name: Run the Testim Tests 
          command:   |
            nvm list
            npm i -g @testim/testim-cli
            cd /home/circleci/project/qa-regression
            testim --report-file $CIRCLE_TEST_REPORTS/testim/results.xml -c airflowui_testim_config.js
      - store_artifacts:
          path: /tmp/circleci-test-results
      - store_test_results:
          path: /tmp/circleci-test-results
  certified-core-dags:
    description: "Run Core DAGS"
    environment:
      CORE_TEST_REPORTS: /tmp/core-test-results
    executor: machine-executor
    steps:
      - run: sudo apt-get -y update
      - run: sudo apt-get -y install git
      - run: sudo apt-get -y install curl
      - run: curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash -
      - run: sudo apt-get install nodejs
      - run: npm -v
      - run: nodejs -v
      - run: 
          name: Avoid hosts unknown for github
          command:   | 
            [ ! -d ~/.ssh ] && mkdir ~/.ssh/
            echo -e "Host github.com\n\tStrictHostKeyChecking no\n" > ~/.ssh/config  
      - run: git clone git@github.com:astronomer/qa-regression.git
      - run: git clone git@github.com:astronomer/qa-regression.git
      - run: 
          name: Run Shell Script for creating deployment
          command:  |
            cd qa-regression
            ls
            chmod 744 create_deployment.sh
            bash ./create_deployment.sh
            cd ..
      - run: 
          name: Run the Python Script to run DAGS 
          command:   |
            nvm list
            npm i -g @testim/testim-cli
            cd /home/circleci/project/qa-regression
            testim --report-file $CIRCLE_TEST_REPORTS/testim/results.xml -c airflowui_testim_config.js
      - store_artifacts:
          path: /tmp/core-test-results
      - store_test_results:
          path: /tmp/core-test-results
  wait_workflow_orb:
    description: |
        This command waits for running workflows of a kind on a given branch to complete. Adding This
        as the first step in a job will make the job wait till it is the only running workflow.
        This requires a Circle CI token be set as $CIRCLE_TOKEN
    parameters:
        branch-to-consider:
            default: master
            description: The branch on which we will wait for workflows. If set to "all" this will wait across all branches
            type: string
        kill-gracefully:
            default: "true"
            description: If true and time exceeds max wait time, dies without failing the job
            type: string
        max-wait-time:
            default: "600"
            description: |
                The max wait time in seconds a job should wait for before killing itself.
            type: string
        run-on-branch:
            default: '*'
            description: |
                The branches to actually wait on. By default this waits on all branches. If set to anything but
                '*' the wait will run only on the specified branch
            type: string
        sleep-time-between-checks:
            default: "30"
            description: How long to sleep between checks.
            type: string
        vcs-type:
            default: github
            description: What is the VCS for this project
            type: string
        workflow-name:
            default: '*'
            description: The type of workflows to wait for. This can be a regex
            type: string
    steps:
        - run:
            command: |
                if [ -z "$BASH" ]; then
                  echo Bash not installed.
                  exit 1
                fi
                hash jq 2>/dev/null || { echo >&2 "jq is not installed.  Aborting."; exit 1; }
                if [[ "$CIRCLE_TOKEN" == "" ]]; then
                  echo "CIRCLE_TOKEN not set. Set a token to access the circle API in the env var CIRCLE_TOKEN";
                  exit 1;
                fi

                if [[ "<< parameters.run-on-branch >>" != "*" && "<< parameters.run-on-branch >>" != "$CIRCLE_BRANCH" ]]; then
                  echo "Chosen to run only on << parameters.run-on-branch >> and currently we are on $CIRCLE_BRANCH, exiting";
                  exit 0;
                fi

                slug="<< parameters.vcs-type >>/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}"
                branch_to_consider="<< parameters.branch-to-consider >>"

                # Assume there is one workflow running.
                total_workflows_running="1"
                can_i_run="true"

                mkdir -p /tmp/swissknife

                # This is a global variable used to get return value for get_workflow_start_time
                workflow_start_time=""

                get_workflow_start_time() {
                  wf_url="https://circleci.com/api/v2/workflow/%7B$1%7D?circle-token=${CIRCLE_TOKEN}"
                  echo $wf_url
                  curl -f -s $wf_url > /tmp/swissknife/wf_$1.json
                  workflow_start_time=$(jq '.created_at' /tmp/swissknife/wf_$1.json)
                  echo "Reached"
                }

                echo "Er:"$workflow_start_time

                get_num_running_workflows() {
                  running_job_prefix="https://circleci.com/api/v1.1/project/$slug";
                  running_jobs_suffix="?circle-token=${CIRCLE_TOKEN}&filter=running&limit=100";
                  running_jobs_branch="";
                  if [[ "$branch_to_consider" != "all" ]]; then
                    running_jobs_branch="/tree/$branch_to_consider";
                  fi
                  running_jobs_url="${running_job_prefix}${running_jobs_branch}${running_jobs_suffix}"
                  echo "ER:"$running_jobs_url
                  curl -f -s $running_jobs_url > /tmp/swissknife/running_jobs.json
                  total_workflows_running=$(jq --arg curworkflow "$CIRCLE_WORKFLOW_ID" '[unique_by(.workflows.workflow_id) | .[] | select(.workflows.workflow_name|test("<< parameters.workflow-name >>")) | select(.workflows.workflow_id|test($curworkflow)|not) ] | length' /tmp/swissknife/running_jobs.json)
                  # If no other workflows are running, we're good. just return
                  if [ "$total_workflows_running" == "0" ]; then
                    return 0
                  fi
                  echo "ER:Completed -JQ1"
                  # Finding all running workflows
                  jq -r --arg curworkflow "$CIRCLE_WORKFLOW_ID" 'unique_by(.workflows.workflow_id) | .[] | select(.workflows.workflow_name|test("<< parameters.workflow-name >>")) | select(.workflows.workflow_id|test($curworkflow)|not) | .workflows.workflow_id' /tmp/swissknife/running_jobs.json > /tmp/swissknife/running_workflows.txt
                  cat /tmp/swissknife/running_workflows.txt
                  echo "ER:Completed -JQ2"
                  # get_workflow_start_time $CIRCLE_WORKFLOW_ID
                  # current_workflow_start_time=$workflow_start_time
                  echo "ER:Completed -JQ3"
                  can_i_run="false"
                  # while IFS= read -r line
                  # do
                  #   echo "Checking info for workflow:$line"
                  #   get_workflow_start_time $line
                  #   running_wf_start_time=$workflow_start_time
                  #   if [[ $running_wf_start_time < $current_workflow_start_time ]] ; then
                  #     can_i_run="false"
                  #     break
                  #   fi
                  # done < /tmp/swissknife/running_workflows.txt

                  echo "ER:Completed"
                }

                kill_workflow(){
                  echo "Cancelleing workflow by cancelling build ${CIRCLE_BUILD_NUM}"
                  cancel_workflow_url="https://circleci.com/api/v1.1/project/$slug/${CIRCLE_BUILD_NUM}/cancel?circle-token=${CIRCLE_TOKEN}"
                  curl -s -X POST $cancel_workflow_url > /dev/null
                  # Give Circle CI enough time to kill this workflow
                  sleep 30
                  # If the job wasnt canceled in 30 seconds fail.
                  exit 1;
                }

                current_wait_time=0

                while true; do
                  get_num_running_workflows
                  echo "Enter Loop"
                  if [[ "$total_workflows_running" == "0" || "$can_i_run" == "true" ]]; then
                    echo "$total_workflows_running"
                    echo "$can_i_run"
                    echo "Its finally my turn. exiting"
                    exit 0
                  else
                    echo "Looks like $total_workflows_running are still running. and can_i_run:$can_i_run"
                    echo "Going to sleep for << parameters.sleep-time-between-checks >>"
                    sleep << parameters.sleep-time-between-checks >>
                    current_wait_time=$(( current_wait_time + << parameters.sleep-time-between-checks >> ))
                  fi

                  if (( $current_wait_time > << parameters.max-wait-time >> )); then
                    if [[ "<< parameters.kill-gracefully >>" == "true" ]]; then
                      echo "Killing workflow by cancelling";
                      kill_workflow
                    else
                      echo "Killing workflow by exiting forcefully";
                      exit 1;
                    fi
                  fi
                done
            name: Swissknife - Wait for workflows - ER

  
  # TODO: move to an Astronomer orbs repo, publish orb.
  # This is to work around an issue in the provided orb https://github.com/ovotech/circleci-orbs/issues/89.
  modified-orb:
    description: "Scan an image for vulnerabilities"
    parameters:
      image:
        type: "string"
        description: "Name of the image to scan"
        default: ""
      image_file:
        type: "string"
        description: "Path to a file of images to scan"
        default: ""
      allowlist:
        type: "string"
        description: "Path to a CVE allowlist"
        default: ""
      severity_threshold:
        type: "string"
        description: "The threshold (equal and above) at which discovered vulnerabilities are reported. May be 'Defcon1', 'Critical', 'High', 'Medium', 'Low', 'Negligible' or 'Unknown'"
        default: "High"
      fail_on_discovered_vulnerabilities:
        type: "boolean"
        description: "Fail command when vulnerabilities at severity equal to or above the threshold are discovered"
        default: true
      fail_on_unsupported_images:
        type: "boolean"
        description: "Fail command when image cannot be scanned for vulnerabilities"
        default: true
      disable_verbose_console_output:
        type: "boolean"
        description: "Disable verbose console output"
        default: false
      docker_tar_dir:
        type: "string"
        description: "Path of directory that Docker tarballs are stored"
        default: "/docker-tars"
    steps:
      - run:
          name: "Vulnerability scan"
          command: |
            #!/usr/bin/env bash

            set -xe

            DOCKER_TAR_DIR="<< parameters.docker_tar_dir >>"

            if [ -z "<< parameters.image_file >><< parameters.image >>" ] && [ -z "$(ls -A "$DOCKER_TAR_DIR" 2>/dev/null)" ]; then
                echo "image_file or image parameters or docker tarballs must be present"
                exit 255
            fi

            REPORT_DIR=/clair-reports
            mkdir $REPORT_DIR

            DB=$(docker run -p 5432:5432 -d arminc/clair-db:latest)
            CLAIR=$(docker run -p 6060:6060 --link "$DB":postgres -d arminc/clair-local-scan:latest)
            CLAIR_SCANNER=$(docker run -v /var/run/docker.sock:/var/run/docker.sock -d ovotech/clair-scanner@sha256:8a4f920b4e7e40dbcec4a6168263d45d3385f2970ee33e5135dd0e3b75d39c75 tail -f /dev/null)

            clair_ip=$(docker exec -it "$CLAIR" hostname -i | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+')
            scanner_ip=$(docker exec -it "$CLAIR_SCANNER" hostname -i | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+')

            if [ -n "<< parameters.allowlist >>" ]; then
                cat "<< parameters.allowlist >>"
                docker cp "<< parameters.allowlist >>" "$CLAIR_SCANNER:/allowlist.yml"

                allowlist="-w /allowlist.yml"
            fi

            function scan() {
                local image=$1
                # replace forward-slashes and colons with underscores
                munged_image=$(echo "$image" | sed 's/\//_/g' | sed 's/:/_/g')
                sanitised_image_filename="${munged_image}.json"
                local ret=0
                local docker_cmd=(docker exec -it "$CLAIR_SCANNER" clair-scanner \
                    --ip "$scanner_ip" \
                    --clair=http://"$clair_ip":6060 \
                    -t "<< parameters.severity_threshold >>" \
                    --report "/$sanitised_image_filename" \
                    --log "/log.json" \
                    --whitelist /allowlist.yml \
                    --reportAll=true \
                    --exit-when-no-features=false \
                    "$image")

                # if verbose output is disabled, analyse status code for more fine-grained output
                if [ "<< parameters.disable_verbose_console_output >>" == "true" ];then
                    "${docker_cmd[@]}" > /dev/null 2>&1 || ret=$?
                else
                    "${docker_cmd[@]}" 2>&1 || ret=$?
                fi
                if [ $ret -eq 0 ]; then
                    echo "No unapproved vulnerabilities"
                elif [ $ret -eq 1 ]; then
                    echo "Unapproved vulnerabilities found"
                    if [ "<< parameters.fail_on_discovered_vulnerabilities >>" == "true" ];then
                        EXIT_STATUS=1
                    fi
                elif [ $ret -eq 5 ]; then
                    echo "Image was not scanned, not supported."
                    if [ "<< parameters.fail_on_unsupported_images >>" == "true" ];then
                        EXIT_STATUS=1
                    fi
                else
                    echo "Unknown clair-scanner return code $ret."
                    EXIT_STATUS=1
                fi

                docker cp "$CLAIR_SCANNER:/$sanitised_image_filename" "$REPORT_DIR/$sanitised_image_filename" || true
            }

            EXIT_STATUS=0

            for entry in "$DOCKER_TAR_DIR"/*.tar; do
                [ -e "$entry" ] || continue
                images=$(docker load -i "$entry" | sed -e 's/Loaded image: //g')
                for image in $images; do
                    scan "$image"
                done
            done

            if [ -n "<< parameters.image_file >>" ]; then
                images=$(cat "<< parameters.image_file >>")
                for image in $images; do
                    scan "$image"
                done
            fi
            if [ -n "<< parameters.image >>" ]; then
                image="<< parameters.image >>"
                scan "$image"
            fi

            exit $EXIT_STATUS
      - store_artifacts:
          path: /clair-reports
